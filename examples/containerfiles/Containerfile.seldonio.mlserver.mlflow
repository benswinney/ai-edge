FROM registry.access.redhat.com/ubi9/python-39:1-143 as env-creator

ARG MODEL_DIR=.

USER root

# Install miniconda as a helper to create a portable python environment
RUN mkdir -p ~/miniconda3 && \
  wget --show-progress=off https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh && \
  bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3 && \
  rm -rf ~/miniconda3/miniconda.sh

# CHANGE THIS LINE TO MATCH YOUR MODEL
COPY $MODEL_DIR /opt/app-root/src/model/

# Download model dependencies and create a portable tarball
# The tarball is placed inside the model directory.
RUN . ~/miniconda3/bin/activate && \
  conda env create -n mlflow-env -f model/conda.yaml && \
  conda activate mlflow-env && \
  conda list && \
  conda deactivate && \
  conda activate && \
  conda install conda-pack && \
  conda-pack -n mlflow-env -o model/environment.tar.gz

# Create the MLServer container. Use the slim image, since we are providing an environment tarball.
#
FROM docker.io/seldonio/mlserver:1.3.5-slim

ARG MODEL_NAME
ARG GRPC_PORT=9090
ARG REST_PORT=8080
ARG METRICS_PORT=8082

USER root

RUN mkdir /mnt/models/ && chown mlserver:mlserver /mnt/models/

# Copy both the model together with its environment tarball.
COPY --from=env-creator --chown=mlserver:mlserver /opt/app-root/src/model /mnt/models/

RUN chmod o+rwX /mnt/models/
# https://docs.openshift.com/container-platform/4.13/openshift_images/create-images.html#use-uid_create-images
RUN chgrp -R 0 /mnt/models/ && chmod -R g=u /mnt/models/

# Specify that the model is in MLFlow format, and some additional flags.
ENV MLSERVER_MODEL_IMPLEMENTATION=mlserver_mlflow.MLflowRuntime MLSERVER_HTTP_PORT=$REST_PORT MLSERVER_GRPC_PORT=$GRPC_PORT MLSERVER_METRICS_PORT=$METRICS_PORT
# CHANGE THIS LINE TO MATCH YOUR MODEL
ENV MLSERVER_MODEL_URI=/mnt/models MLSERVER_MODEL_NAME=$MODEL_NAME

EXPOSE $REST_PORT $GRPC_PORT $METRICS_PORT

USER mlserver
